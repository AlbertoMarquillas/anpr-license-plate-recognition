# anpr-license-plate-recognition

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Conventional Commits](https://img.shields.io/badge/Conventional%20Commits-1.0.0-green.svg)](https://conventionalcommits.org)
[![Python](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://www.python.org/)
[![Release](https://img.shields.io/badge/release-v0.1.0-orange.svg)](../../releases)

---

## ğŸ“– Overview

This repository provides an **Automatic Number Plate Recognition (ANPR)** pipeline built with:

* **YOLOv3 (OpenCV DNN module)** for license plate detection.
* **EasyOCR** for character recognition.

The system detects license plates in images, crops them, applies preprocessing, and uses OCR to extract alphanumeric text. This is a **portfolio-ready implementation**, showcasing end-to-end computer vision and text recognition.

---

## ğŸ“‚ Repository Structure

```
anpr-license-plate-recognition/
â”œâ”€ src/                 # Source code (main pipeline, utils)
â”‚   â”œâ”€ main.py          # Entrypoint with CLI
â”‚   â””â”€ util.py          # Helper functions (NMS, draw, outputs)
â”œâ”€ configs/
â”‚   â””â”€ default.yaml     # Default configuration (paths, thresholds)
â”œâ”€ models/              # YOLOv3 model assets
â”‚   â”œâ”€ config/          # darknet-yolov3.cfg
â”‚   â”œâ”€ weights/         # model.weights
â”‚   â””â”€ classes.names    # classes file
â”œâ”€ data/                # Sample images (ignored in .git)
â”‚   â””â”€ README.md        # Instructions for placing datasets
â”œâ”€ notebooks/           # (Optional) experiments, EDA
â”œâ”€ docs/                # Documentation
â”‚   â””â”€ assets/          # Figures, diagrams
â”œâ”€ build/               # Outputs (annotated images, logs)
â””â”€ README.md            # Project documentation
```

---

## âš™ï¸ Getting Started

### Prerequisites

* **Python 3.10+**
* [Tesseract OCR](https://github.com/tesseract-ocr/tesseract) installed and added to PATH (required by EasyOCR on some systems).
* GPU optional (OpenCV DNN runs on CPU by default).

### Installation

```powershell
# Clone repository
git clone https://github.com/AlbertoMarquillas/anpr-license-plate-recognition.git
cd anpr-license-plate-recognition

# (Optional) create virtual environment
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# Install dependencies
pip install -r requirements.txt

# If requirements.txt not present, install manually
pip install opencv-python easyocr numpy pyyaml matplotlib
```

### Folder setup

* Place YOLOv3 model files in `models/`:

  * `models/config/darknet-yolov3.cfg`
  * `models/weights/model.weights`
  * `models/classes.names`
* Place input images in `data/`.

---

## â–¶ï¸ Usage

Run the pipeline with default settings (YAML config):

```powershell
python .\src\main.py --save --show
```

Specify arguments explicitly:

```powershell
python .\src\main.py `
  --input-dir data `
  --model-dir models `
  --cfg config/darknet-yolov3.cfg `
  --weights weights/model.weights `
  --classes classes.names `
  --langs en `
  --save --show
```

Key options:

* `--save` â†’ Save annotated outputs in `build/outputs/`.
* `--show` â†’ Display annotated images interactively.
* `--langs` â†’ Specify EasyOCR languages, e.g., `--langs en es`.

---

## ğŸ“Š Example Output

Detected plate text with confidence scores printed in terminal, and annotated images saved in `build/outputs/`.

```
[car1.jpg] 1234ABC (score=0.89)
[car2.png] 4567XYZ (score=0.83)
```

---

## ğŸ“ Dataset & Models

* **Datasets**: not included. Place your own test images in `data/`.
* **Models**: not included. Add YOLOv3 config, weights, and classes to `models/`.
* See `data/README.md` and `models/README.md` for detailed instructions.

---

## âœ¨ Features

* License plate detection using **YOLOv3 + OpenCV DNN**.
* Non-Maximum Suppression (NMS) for cleaner bounding boxes.
* Plate preprocessing (grayscale, thresholding).
* Text recognition with **EasyOCR**.
* CLI with PowerShell examples.
* Configurable thresholds and model paths via YAML.
* Portfolio-ready repo structure and documentation.

---

## ğŸ“š What I Learned

* Building an **end-to-end ANPR system** combining detection + OCR.
* Using **OpenCV DNN** to load and run YOLO models.
* Handling detection outputs, confidence thresholds, and NMS.
* Integrating **EasyOCR** for multilingual text recognition.
* Designing a **portfolio-friendly project structure** for recruiters.

---

## ğŸš€ Roadmap

* [ ] Add Dockerfile for reproducible environments.
* [ ] Expand support for YOLOv5/YOLOv8 detection.
* [ ] Integrate video stream input (real-time ANPR).
* [ ] Add unit tests in `test/`.
* [ ] Pretrained model links via GitHub Releases.

---

## ğŸ“ License

This project is licensed under the [MIT License](LICENSE).
